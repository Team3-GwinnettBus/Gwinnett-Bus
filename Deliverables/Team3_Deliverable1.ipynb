{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\" font-family: Babas; font-size: 2em;\">Team 3 <br> Deliverable 1</span>\n",
        " <span style=\" font-size: 1.5em;\"><br> Initial Development of Kafka Consumer, Producer, and Data Processing.<br></span>\n",
        " Michael Rizig, Sam Bostian, Charlie McLarty, Brian Pruitt, Allen Roman\n",
        "\n",
        " Abstract: In this deliverable, we have 3 elements: The Kafka Server (not in this file), <b>Kafka Producer (Producer.py)</b>, and <b>Kafka Consumer (Consumer.py)</b>. This guide will go through each file line step by step, and expand on what each script is doing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\" font-size: 1.5em;\">Producer.py:<br></span>\n",
        "The Producer.py file \"produces\" and feeds data into the Kafka server for real-time distribution.\n",
        "\n",
        "Step 1: Import Kafka native API for python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from kafka import KafkaProducer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 2: Define server address and desired topic on said server:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "TOPICNAME = 'GCPS_Bus_Monitoring'\n",
        "SERVERIP = 'localhost:9092' #insert server ip here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 3: Connect to the server via Kafka producer object and pass ip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "producer = KafkaProducer(bootstrap_servers=SERVERIP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 4: Publish data to the topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "producer.send(TOPICNAME,b'data')\n",
        "producer.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thats it! This is the basic concept of the producer file. <b>In application, this producer would resemble the buses sending their location and id data to the Kafka server</b>, which would in turn pass that data to every 'consumer' subscribed to that topic. This style of 'producer' and 'consumer' design follows the [Publish-Subcribe Paradigme](https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span style=\" font-size: 1.5em;\">Consumer.py:<br></span>\n",
        "The Consumer.py file \"consumes\" the real-time data. In this demo, it simply prints the data to the console, but in application, this file would determine which bus a given event belongs to and insert the data received from that event into the relational database with the correct primary/foreign key (depending on the database scheme).\n",
        "\n",
        "Step 1: Import Kafka native API for python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from kafka import KafkaConsumer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 2: Define server address and desired topic on said server:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "TOPICNAME = 'GCPS_Bus_Monitoring'\n",
        "SERVERIP = 'localhost:9092' #insert server ip here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 3: Connect to he server via Kafka consumer object and pass desired topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "consumer = KafkaConsumer(TOPICNAME, bootstrap_servers=SERVERIP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 4: Parse data:\n",
        "(<b>In application, this loop would parse the JSON, find the bus id, and <u>insert the data into the relational database</u>, but for demo purposes, the loop simply prints the data to the console.</b>)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "for messages in consumer:\n",
        "    print(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And thats it. This small example demonstrates the basic idea of the kakfa live event streaming api."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
